"""
Technical Indicators Performance Test
æŠ€è¡“æŒ‡æ¨™æ€§èƒ½æ¸¬è©¦ - æ¸¬è©¦ 4000+ è‚¡ç¥¨çš„è¨ˆç®—æ€§èƒ½
"""

import pandas as pd
import numpy as np
import sys
import os
from pathlib import Path
import time
import logging
from typing import Dict, List, Tuple, Any
import json
from datetime import datetime
import multiprocessing as mp
import psutil
import warnings

warnings.filterwarnings("ignore")

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

# Import components
from src.indicators.indicator_calculator import IndicatorCalculator, CalculationConfig
from src.indicators.signal_generator import IndicatorSignalGenerator

logger = logging.getLogger(__name__)


class PerformanceProfiler:
    """æ€§èƒ½åˆ†æå™¨"""

    def __init__(self):
        self.metrics = {}
        self.system_info = self._get_system_info()

    def _get_system_info(self) -> Dict[str, Any]:
        """ç²å–ç³»çµ±ä¿¡æ¯"""
        return {
            "cpu_count": mp.cpu_count(),
            "cpu_percent": psutil.cpu_percent(interval=1),
            "memory_total_gb": round(psutil.virtual_memory().total / (1024**3), 2),
            "memory_available_gb": round(psutil.virtual_memory().available / (1024**3), 2),
            "python_version": sys.version.split()[0],
        }

    def profile_function(self, func, *args, **kwargs):
        """åˆ†æå‡½æ•¸æ€§èƒ½"""
        # è¨˜éŒ„é–‹å§‹ç‹€æ…‹
        process = psutil.Process()
        start_memory = process.memory_info().rss / (1024**2)  # MB
        process.cpu_percent()
        start_time = time.time()

        # åŸ·è¡Œå‡½æ•¸
        result = func(*args, **kwargs)

        # è¨˜éŒ„çµæŸç‹€æ…‹
        end_time = time.time()
        end_memory = process.memory_info().rss / (1024**2)  # MB
        end_cpu = process.cpu_percent()

        execution_time = end_time - start_time
        memory_used = end_memory - start_memory

        return result, {
            "execution_time": execution_time,
            "memory_used_mb": memory_used,
            "peak_memory_mb": end_memory,
            "cpu_percent": end_cpu,
        }


class DataGenerator:
    """æ¸¬è©¦æ•¸æ“šç”Ÿæˆå™¨"""

    @staticmethod
    def generate_stock_universe(
        n_stocks: int = 4000, n_periods: int = 252
    ) -> Dict[str, pd.DataFrame]:
        """
        ç”Ÿæˆè‚¡ç¥¨æ± æ•¸æ“š

        Args:
            n_stocks: è‚¡ç¥¨æ•¸é‡
            n_periods: æ™‚é–“é€±æœŸæ•¸ï¼ˆé»˜èªä¸€å¹´äº¤æ˜“æ—¥ï¼‰

        Returns:
            è‚¡ç¥¨æ•¸æ“šå­—å…¸
        """
        print(f"Generating {n_stocks} stocks with {n_periods} periods each...")

        stocks_data = {}
        np.random.seed(42)  # ç¢ºä¿å¯é‡ç¾æ€§

        # é å®šç¾©ä¸€äº›è‚¡ç¥¨ç‰¹æ€§
        stock_profiles = [
            {"volatility": 0.15, "trend": 0.08, "name": "growth"},  # æˆé•·è‚¡
            {"volatility": 0.25, "trend": 0.12, "name": "tech"},  # ç§‘æŠ€è‚¡
            {"volatility": 0.10, "trend": 0.05, "name": "utility"},  # å…¬ç”¨äº‹æ¥­
            {"volatility": 0.20, "trend": 0.06, "name": "finance"},  # é‡‘èè‚¡
            {"volatility": 0.30, "trend": 0.03, "name": "energy"},  # èƒ½æºè‚¡
            {"volatility": 0.18, "trend": 0.07, "name": "healthcare"},  # é†«ç™‚è‚¡
        ]

        for i in range(n_stocks):
            symbol = f"STOCK{i:04d}"

            # é¸æ“‡è‚¡ç¥¨ç‰¹æ€§
            profile = stock_profiles[i % len(stock_profiles)]

            # ç”Ÿæˆåƒ¹æ ¼æ•¸æ“š
            dates = pd.date_range(start="2023-01-01", periods=n_periods, freq="1D")

            # ä½¿ç”¨å¹¾ä½•å¸ƒæœ—é‹å‹•æ¨¡æ“¬åƒ¹æ ¼
            dt = 1 / 252  # ä¸€å¤©
            mu = profile["trend"]  # å¹´åŒ–æ”¶ç›Šç‡
            sigma = profile["volatility"]  # å¹´åŒ–æ³¢å‹•ç‡

            # ç”Ÿæˆéš¨æ©ŸéŠèµ°
            dW = np.random.normal(0, np.sqrt(dt), n_periods)

            # åˆå§‹åƒ¹æ ¼
            S0 = np.random.uniform(10, 500)  # 10-500 ç¾å…ƒ

            # å¹¾ä½•å¸ƒæœ—é‹å‹•
            returns = (mu - 0.5 * sigma**2) * dt + sigma * dW
            prices = S0 * np.exp(np.cumsum(returns))

            # ç”Ÿæˆ OHLC æ•¸æ“š
            high_noise = np.abs(np.random.normal(0, sigma * S0 * 0.01, n_periods))
            low_noise = np.abs(np.random.normal(0, sigma * S0 * 0.01, n_periods))

            pd.DataFrame(
                {
                    "open": prices + np.random.normal(0, sigma * S0 * 0.005, n_periods),
                    "high": prices + high_noise,
                    "low": prices - low_noise,
                    "close": prices,
                    "volume": np.random.lognormal(
                        mean=np.log(1000000), sigma=0.5, size=n_periods
                    ).astype(int),
                },
                index=dates,
            )

            # ç¢ºä¿ OHLC é‚è¼¯æ­£ç¢º
            data["high"] = np.maximum.reduce(
                [data["open"], data["high"], data["low"], data["close"]]
            )
            data["low"] = np.minimum.reduce(
                [data["open"], data["high"], data["low"], data["close"]]
            )

            stocks_data[symbol] = data

            # é€²åº¦æç¤º
            if (i + 1) % 1000 == 0:
                print(f"  Generated {i + 1}/{n_stocks} stocks...")

        print(f"âœ“ Generated {n_stocks} stocks successfully")
        return stocks_data


class PerformanceTestSuite:
    """æ€§èƒ½æ¸¬è©¦å¥—ä»¶"""

    def __init__(self):
        self.profiler = PerformanceProfiler()
        self.results = {
            "system_info": self.profiler.system_info,
            "test_results": {},
            "timestamp": datetime.now().isoformat(),
        }

    def test_single_stock_performance(self) -> Dict[str, Any]:
        """æ¸¬è©¦å–®è‚¡ç¥¨æŒ‡æ¨™è¨ˆç®—æ€§èƒ½"""
        print("\nğŸ” Testing single stock indicator calculation performance...")

        # ç”Ÿæˆå–®è‚¡æ¸¬è©¦æ•¸æ“š
        test_data = DataGenerator.generate_stock_universe(n_stocks=1, n_periods=1000)
        stock_data = list(test_data.values())[0]

        # åˆå§‹åŒ–è¨ˆç®—å™¨
        config = CalculationConfig(
            timeframes=["1d"], use_multiprocessing=False, cache_results=False
        )
        calculator = IndicatorCalculator(config)

        # æ¸¬è©¦å„å€‹æŒ‡æ¨™çš„è¨ˆç®—æ™‚é–“
        indicator_times = {}

        for indicator_name, indicator in calculator.indicators.items():
            try:
                result, metrics = self.profiler.profile_function(indicator.calculate, stock_data)

                indicator_times[indicator_name] = {
                    "execution_time_ms": metrics["execution_time"] * 1000,
                    "memory_used_mb": metrics["memory_used_mb"],
                    "result_size": len(result) if hasattr(result, "__len__") else 1,
                }

                print(f"  {indicator_name}: {metrics['execution_time']*1000:.2f}ms")

            except Exception as e:
                indicator_times[indicator_name] = {"error": str(e)}
                print(f"  {indicator_name}: ERROR - {e}")

        # è¨ˆç®—çµ±è¨ˆ
        valid_times = [
            r["execution_time_ms"] for r in indicator_times.values() if "execution_time_ms" in r
        ]

        summary = {
            "total_indicators": len(calculator.indicators),
            "successful_calculations": len(valid_times),
            "avg_time_ms": np.mean(valid_times) if valid_times else 0,
            "max_time_ms": np.max(valid_times) if valid_times else 0,
            "min_time_ms": np.min(valid_times) if valid_times else 0,
            "total_time_ms": np.sum(valid_times) if valid_times else 0,
            "indicator_times": indicator_times,
        }

        print(f"âœ“ Single stock test completed - Avg: {summary['avg_time_ms']:.2f}ms per indicator")
        return summary

    def test_batch_calculation_performance(self) -> Dict[str, Any]:
        """æ¸¬è©¦æ‰¹é‡è¨ˆç®—æ€§èƒ½"""
        print("\nğŸ“Š Testing batch calculation performance...")

        # ä¸åŒè¦æ¨¡çš„æ¸¬è©¦
        test_scales = [10, 50, 100, 500, 1000]
        batch_results = {}

        for n_stocks in test_scales:
            print(f"  Testing {n_stocks} stocks...")

            # ç”Ÿæˆæ¸¬è©¦æ•¸æ“š
            stocks_data = DataGenerator.generate_stock_universe(
                n_stocks=n_stocks, n_periods=252  # ä¸€å¹´æ•¸æ“š
            )

            # é…ç½®è¨ˆç®—å™¨
            config = CalculationConfig(
                timeframes=["1d"],
                batch_size=min(50, n_stocks),
                use_multiprocessing=n_stocks > 50,
                max_workers=min(4, mp.cpu_count()),
                cache_results=True,
            )

            calculator = IndicatorCalculator(config)

            # åŸ·è¡Œæ‰¹é‡è¨ˆç®—
            result, metrics = self.profiler.profile_function(
                calculator.calculate_all_indicators, stocks_data
            )

            # è¨ˆç®—æ€§èƒ½æŒ‡æ¨™
            batch_results[n_stocks] = {
                "execution_time_s": metrics["execution_time"],
                "memory_used_mb": metrics["memory_used_mb"],
                "peak_memory_mb": metrics["peak_memory_mb"],
                "stocks_per_second": n_stocks / metrics["execution_time"],
                "indicators_per_second": (n_stocks * len(calculator.indicators))
                / metrics["execution_time"],
                "memory_per_stock_mb": metrics["peak_memory_mb"] / n_stocks,
                "successful_calculations": len([r for r in result.values() if r]),
            }

            print(
                f"    {n_stocks} stocks: {metrics['execution_time']:.2f}s, "
                f"{batch_results[n_stocks]['stocks_per_second']:.1f} stocks/s"
            )

        return batch_results

    def test_multiprocessing_scaling(self) -> Dict[str, Any]:
        """æ¸¬è©¦å¤šé€²ç¨‹æ“´å±•æ€§èƒ½"""
        print("\nâš¡ Testing multiprocessing scaling performance...")

        # ç”Ÿæˆå›ºå®šæ¸¬è©¦æ•¸æ“š
        test_stocks = 200
        stocks_data = DataGenerator.generate_stock_universe(n_stocks=test_stocks, n_periods=252)

        scaling_results = {}
        worker_counts = [1, 2, 4, mp.cpu_count()]

        for workers in worker_counts:
            print(f"  Testing with {workers} worker(s)...")

            config = CalculationConfig(
                timeframes=["1d"],
                batch_size=25,
                use_multiprocessing=workers > 1,
                max_workers=workers,
                cache_results=False,  # é¿å…ç·©å­˜å½±éŸ¿
            )

            calculator = IndicatorCalculator(config)

            # åŸ·è¡Œè¨ˆç®—
            result, metrics = self.profiler.profile_function(
                calculator.calculate_all_indicators, stocks_data
            )

            scaling_results[workers] = {
                "execution_time_s": metrics["execution_time"],
                "speedup": None,  # ç¨å¾Œè¨ˆç®—
                "efficiency": None,  # ç¨å¾Œè¨ˆç®—
                "memory_used_mb": metrics["memory_used_mb"],
                "successful_calculations": len([r for r in result.values() if r]),
            }

            print(f"    {workers} workers: {metrics['execution_time']:.2f}s")

        # è¨ˆç®—åŠ é€Ÿæ¯”å’Œæ•ˆç‡
        baseline_time = scaling_results[1]["execution_time_s"]
        for workers in scaling_results:
            time_taken = scaling_results[workers]["execution_time_s"]
            speedup = baseline_time / time_taken
            efficiency = speedup / workers

            scaling_results[workers]["speedup"] = speedup
            scaling_results[workers]["efficiency"] = efficiency

        return scaling_results

    def test_memory_efficiency(self) -> Dict[str, Any]:
        """æ¸¬è©¦è¨˜æ†¶é«”æ•ˆç‡"""
        print("\nğŸ’¾ Testing memory efficiency...")

        memory_results = {}
        stock_counts = [100, 500, 1000, 2000]

        for n_stocks in stock_counts:
            print(f"  Testing memory usage with {n_stocks} stocks...")

            # ç›£æ§è¨˜æ†¶é«”ä½¿ç”¨
            process = psutil.Process()
            initial_memory = process.memory_info().rss / (1024**2)  # MB

            # ç”Ÿæˆæ•¸æ“š
            stocks_data = DataGenerator.generate_stock_universe(n_stocks=n_stocks, n_periods=252)

            data_memory = process.memory_info().rss / (1024**2) - initial_memory

            # è¨ˆç®—æŒ‡æ¨™
            config = CalculationConfig(
                timeframes=["1d"], use_multiprocessing=False, cache_results=False
            )
            calculator = IndicatorCalculator(config)

            results = calculator.calculate_all_indicators(stocks_data)

            final_memory = process.memory_info().rss / (1024**2)
            calculation_memory = final_memory - initial_memory - data_memory

            memory_results[n_stocks] = {
                "data_memory_mb": data_memory,
                "calculation_memory_mb": calculation_memory,
                "total_memory_mb": final_memory - initial_memory,
                "memory_per_stock_mb": (final_memory - initial_memory) / n_stocks,
                "memory_efficiency": calculation_memory / data_memory if data_memory > 0 else 0,
            }

            print(
                f"    {n_stocks} stocks: Data: {data_memory:.1f}MB, "
                f"Calc: {calculation_memory:.1f}MB, Total: {final_memory - initial_memory:.1f}MB"
            )

            # æ¸…ç†è¨˜æ†¶é«”
            del stocks_data
            del results

        return memory_results

    def test_large_scale_performance(self) -> Dict[str, Any]:
        """æ¸¬è©¦å¤§è¦æ¨¡æ€§èƒ½ï¼ˆ4000+ è‚¡ç¥¨ï¼‰"""
        print("\nğŸš€ Testing large-scale performance (4000+ stocks)...")

        # ç”Ÿæˆ 4000 è‚¡ç¥¨æ•¸æ“š
        n_stocks = 4000
        print(f"Generating {n_stocks} stocks (this may take a few minutes)...")

        stocks_data = DataGenerator.generate_stock_universe(n_stocks=n_stocks, n_periods=252)

        # é…ç½®è¨ˆç®—å™¨ä»¥ç²å¾—æœ€ä½³æ€§èƒ½
        config = CalculationConfig(
            timeframes=["1d"],
            batch_size=100,
            use_multiprocessing=True,
            max_workers=min(8, mp.cpu_count()),
            cache_results=True,
        )

        calculator = IndicatorCalculator(config)

        print(f"Calculating indicators for {n_stocks} stocks...")

        # åŸ·è¡Œå¤§è¦æ¨¡è¨ˆç®—
        result, metrics = self.profiler.profile_function(
            calculator.calculate_all_indicators, stocks_data
        )

        # ç²å–æ€§èƒ½çµ±è¨ˆ
        perf_stats = calculator.get_performance_stats()

        large_scale_results = {
            "total_stocks": n_stocks,
            "execution_time_s": metrics["execution_time"],
            "memory_used_mb": metrics["memory_used_mb"],
            "peak_memory_mb": metrics["peak_memory_mb"],
            "stocks_per_second": n_stocks / metrics["execution_time"],
            "total_indicators_calculated": perf_stats["total_calculations"],
            "cache_hit_rate": perf_stats["cache_hit_rate"],
            "avg_time_per_stock_ms": (metrics["execution_time"] * 1000) / n_stocks,
            "memory_per_stock_mb": metrics["peak_memory_mb"] / n_stocks,
            "successful_stocks": len([r for r in result.values() if r]),
            "success_rate": len([r for r in result.values() if r]) / n_stocks,
        }

        print("âœ“ Large-scale test completed:")
        print(f"  Time: {metrics['execution_time']:.1f}s")
        print(f"  Speed: {large_scale_results['stocks_per_second']:.1f} stocks/s")
        print(f"  Memory: {metrics['peak_memory_mb']:.1f}MB peak")
        print(f"  Success rate: {large_scale_results['success_rate']*100:.1f}%")

        return large_scale_results

    def run_all_tests(self) -> Dict[str, Any]:
        """é‹è¡Œæ‰€æœ‰æ€§èƒ½æ¸¬è©¦"""
        print("Technical Indicators Performance Test Suite")
        print("=" * 60)
        print(
            f"ğŸ–¥ï¸  System: {self.profiler.system_info['cpu_count']} CPUs, "
            f"{self.profiler.system_info['memory_total_gb']}GB RAM"
        )
        print("-" * 60)

        try:
            # é‹è¡Œå„é …æ¸¬è©¦
            self.results["test_results"]["single_stock"] = self.test_single_stock_performance()
            self.results["test_results"][
                "batch_calculation"
            ] = self.test_batch_calculation_performance()
            self.results["test_results"][
                "multiprocessing_scaling"
            ] = self.test_multiprocessing_scaling()
            self.results["test_results"]["memory_efficiency"] = self.test_memory_efficiency()
            self.results["test_results"]["large_scale"] = self.test_large_scale_performance()

            # ç”Ÿæˆæ€§èƒ½å ±å‘Š
            self.generate_performance_report()

            print("\nğŸ‰ All performance tests completed successfully!")

        except Exception as e:
            print(f"\nâŒ Performance test failed: {e}")
            logger.error(f"Performance test error: {e}")
            self.results["error"] = str(e)

        return self.results

    def generate_performance_report(self):
        """ç”Ÿæˆæ€§èƒ½å ±å‘Š"""
        report_file = Path(__file__).parent / "performance_test_results.json"

        with open(report_file, "w") as f:
            json.dump(self.results, f, indent=2, default=str)

        # ç”Ÿæˆç°¡åŒ–å ±å‘Š
        summary_file = Path(__file__).parent / "performance_summary.txt"

        with open(summary_file, "w") as f:
            f.write("Technical Indicators Performance Test Summary\n")
            f.write("=" * 50 + "\n\n")

            f.write(f"Test Date: {self.results['timestamp']}\n")
            f.write(
                f"System: {self.profiler.system_info['cpu_count']} CPUs, "
                f"{self.profiler.system_info['memory_total_gb']}GB RAM\n\n"
            )

            # å¤§è¦æ¨¡æ¸¬è©¦çµæœ
            if "large_scale" in self.results["test_results"]:
                large = self.results["test_results"]["large_scale"]
                f.write("ğŸš€ Large-Scale Performance (4000 stocks):\n")
                f.write(f"  Execution Time: {large['execution_time_s']:.1f} seconds\n")
                f.write(f"  Processing Speed: {large['stocks_per_second']:.1f} stocks/second\n")
                f.write(f"  Memory Usage: {large['peak_memory_mb']:.1f} MB\n")
                f.write(f"  Success Rate: {large['success_rate']*100:.1f}%\n\n")

            # å–®è‚¡ç¥¨æ€§èƒ½
            if "single_stock" in self.results["test_results"]:
                single = self.results["test_results"]["single_stock"]
                f.write("ğŸ” Single Stock Performance:\n")
                f.write(f"  Average per indicator: {single['avg_time_ms']:.2f}ms\n")
                f.write(f"  Total indicators: {single['total_indicators']}\n")
                f.write(
                    f"  Success rate: {single['successful_calculations']}/{single['total_indicators']}\n\n"
                )

            # å¤šé€²ç¨‹æ“´å±•æ€§
            if "multiprocessing_scaling" in self.results["test_results"]:
                scaling = self.results["test_results"]["multiprocessing_scaling"]
                f.write("âš¡ Multiprocessing Scaling:\n")
                for workers, data in scaling.items():
                    f.write(
                        f"  {workers} workers: {data['speedup']:.2f}x speedup, "
                        f"{data['efficiency']*100:.1f}% efficiency\n"
                    )

        print(f"\nğŸ“Š Performance report saved to: {report_file}")
        print(f"ğŸ“‹ Summary saved to: {summary_file}")


def main():
    """ä¸»å‡½æ•¸"""
    test_suite = PerformanceTestSuite()
    results = test_suite.run_all_tests()

    # æª¢æŸ¥æ˜¯å¦é”åˆ°æ€§èƒ½è¦æ±‚
    requirements_met = True

    if "large_scale" in results["test_results"]:
        large_scale = results["test_results"]["large_scale"]

        # æ€§èƒ½è¦æ±‚æª¢æŸ¥
        if large_scale["stocks_per_second"] < 50:  # è‡³å°‘50è‚¡ç¥¨/ç§’
            print("âš ï¸  Warning: Processing speed below target (50 stocks/second)")
            requirements_met = False

        if large_scale["success_rate"] < 0.95:  # è‡³å°‘95%æˆåŠŸç‡
            print("âš ï¸  Warning: Success rate below target (95%)")
            requirements_met = False

        if large_scale["peak_memory_mb"] > 8000:  # ä¸è¶…é8GBè¨˜æ†¶é«”
            print("âš ï¸  Warning: Memory usage above target (8GB)")
            requirements_met = False

    if requirements_met:
        print("\nâœ… All performance requirements met!")
        return True
    else:
        print("\nâŒ Some performance requirements not met.")
        return False


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
